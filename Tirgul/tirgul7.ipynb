{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rNuGvi0Uxoh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Text Analysis and Indexing Service\n",
        "This module provides functionality for text analysis, word frequency tracking,\n",
        "and advanced text processing operations.\n",
        "\"\"\"\n",
        "\n",
        "!pip install requests beautifulsoup4\n",
        "!pip install firebase\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "class TextAnalysisService:\n",
        "    \"\"\"\n",
        "    A service class for analyzing and processing text content with advanced features\n",
        "    like stop word removal and word stemming.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize an empty word frequency index.\"\"\"\n",
        "        self.frequency_index = {}\n",
        "\n",
        "    def process_text(self, input_text):\n",
        "        \"\"\"\n",
        "        Process input text and create a frequency index.\n",
        "        \n",
        "        Args:\n",
        "            input_text (str): Text content to analyze\n",
        "        \"\"\"\n",
        "        word_tokens = re.findall(r'\\w+', input_text)\n",
        "        for token in word_tokens:\n",
        "            normalized_token = token.lower()\n",
        "            self.frequency_index[normalized_token] = self.frequency_index.get(normalized_token, 0) + 1\n",
        "\n",
        "    def filter_common_words(self):\n",
        "        \"\"\"Remove common stop words from the frequency index.\"\"\"\n",
        "        common_words = {'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at'}\n",
        "        for common_word in common_words:\n",
        "            self.frequency_index.pop(common_word, None)\n",
        "\n",
        "    def normalize_word_forms(self):\n",
        "        \"\"\"\n",
        "        Apply word stemming to normalize words to their root form.\n",
        "        Uses Porter Stemming algorithm.\n",
        "        \"\"\"\n",
        "        word_stemmer = PorterStemmer()\n",
        "        normalized_index = {}\n",
        "        for word, frequency in self.frequency_index.items():\n",
        "            root_form = word_stemmer.stem(word)\n",
        "            normalized_index[root_form] = normalized_index.get(root_form, 0) + frequency\n",
        "        self.frequency_index = normalized_index\n",
        "\n",
        "    def execute_search(self, search_query):\n",
        "        \"\"\"\n",
        "        Search for terms in the frequency index.\n",
        "        \n",
        "        Args:\n",
        "            search_query (str): Search query string\n",
        "            \n",
        "        Returns:\n",
        "            dict: Dictionary of matching terms and their frequencies\n",
        "        \"\"\"\n",
        "        word_stemmer = PorterStemmer()\n",
        "        query_tokens = re.findall(r'\\w+', search_query.lower())\n",
        "        search_results = {}\n",
        "        for token in query_tokens:\n",
        "            stemmed_token = word_stemmer.stem(token)\n",
        "            if stemmed_token in self.frequency_index:\n",
        "                search_results[stemmed_token] = self.frequency_index[stemmed_token]\n",
        "        return search_results\n",
        "\n",
        "    def get_frequency_index(self):\n",
        "        \"\"\"\n",
        "        Retrieve the current frequency index.\n",
        "        \n",
        "        Returns:\n",
        "            dict: Current word frequency index\n",
        "        \"\"\"\n",
        "        return self.frequency_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6SFemr0VIVL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Web Content Retrieval Module\n",
        "Provides functionality for fetching and parsing web page content.\n",
        "\"\"\"\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def retrieve_webpage_content(target_url):\n",
        "    \"\"\"\n",
        "    Fetch and parse content from a specified URL.\n",
        "    \n",
        "    Args:\n",
        "        target_url (str): The URL to fetch content from\n",
        "        \n",
        "    Returns:\n",
        "        BeautifulSoup: Parsed HTML content or None if fetch fails\n",
        "    \"\"\"\n",
        "    try:\n",
        "        web_response = urlopen(target_url)\n",
        "        return BeautifulSoup(web_response, 'html.parser')\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL-b6XGdZLPp"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Firebase Data Management Service\n",
        "Provides an interface for interacting with Firebase Realtime Database.\n",
        "\"\"\"\n",
        "\n",
        "from firebase import firebase\n",
        "\n",
        "class DatabaseService:\n",
        "    \"\"\"\n",
        "    A service class for managing data operations with Firebase Realtime Database.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, database_url: str):\n",
        "        \"\"\"\n",
        "        Initialize Firebase connection.\n",
        "        \n",
        "        Args:\n",
        "            database_url (str): Firebase database URL\n",
        "        \"\"\"\n",
        "        self.database_connection = firebase.FirebaseApplication(database_url, None)\n",
        "\n",
        "    def store_data(self, storage_path: str, data_payload: dict):\n",
        "        \"\"\"\n",
        "        Store data in Firebase under specified path.\n",
        "        \n",
        "        Args:\n",
        "            storage_path (str): Database path for storage\n",
        "            data_payload (dict): Data to store\n",
        "            \n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.database_connection.put('/', storage_path, data_payload)\n",
        "        print(f\"âœ… Data successfully stored at /{storage_path}\")\n",
        "\n",
        "    def retrieve_data(self, retrieval_path: str):\n",
        "        \"\"\"\n",
        "        Retrieve data from specified Firebase path.\n",
        "        \n",
        "        Args:\n",
        "            retrieval_path (str): Path to retrieve data from\n",
        "            \n",
        "        Returns:\n",
        "            dict: Retrieved data\n",
        "        \"\"\"\n",
        "        retrieved_data = self.database_connection.get(f\"/{retrieval_path}\", None)\n",
        "        print(f\"ðŸ“¥ Data successfully retrieved from /{retrieval_path}\")\n",
        "        return retrieved_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bCl8WWHVtVS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Web Content Analysis System\n",
        "Main execution script that combines web scraping, text analysis, and data storage.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize system components\n",
        "target_website = 'https://www.arianagrande.com/'\n",
        "webpage_content = retrieve_webpage_content(target_website)\n",
        "database_service = DatabaseService(\"https://cloud7-38a0b-default-rtdb.firebaseio.com/\")\n",
        "\n",
        "# Process webpage content and perform analysis\n",
        "if webpage_content:\n",
        "    # Initialize text analysis service\n",
        "    analysis_service = TextAnalysisService()\n",
        "    \n",
        "    # Process webpage content\n",
        "    analysis_service.process_text(webpage_content.get_text())  # Text indexing\n",
        "    analysis_service.filter_common_words()                     # Remove stop words\n",
        "    analysis_service.normalize_word_forms()                    # Apply stemming\n",
        "    \n",
        "    # Execute search for specific terms\n",
        "    search_query = 'shop buy ariana music grande video eternal sunshine brighter days'\n",
        "    analysis_results = analysis_service.execute_search(search_query)\n",
        "\n",
        "    # Display and store results\n",
        "    print(\"Analysis Results:\")\n",
        "    print(analysis_results)\n",
        "    database_service.store_data(\"words\", analysis_results)\n",
        "    print(\"\\nStored Results:\")\n",
        "    print(database_service.retrieve_data(\"words\"))\n",
        "    \n",
        "    # Perform specific word search\n",
        "    specific_query = \"eternal\"\n",
        "    specific_results = analysis_service.execute_search(specific_query)\n",
        "    print(\"\\nðŸ”Ž Search Results for:\", specific_query)\n",
        "    print(specific_results)\n",
        "else:\n",
        "    print(\"Error: Unable to retrieve webpage content\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
